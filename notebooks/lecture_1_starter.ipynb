{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "figured-disclaimer",
   "metadata": {},
   "source": [
    "# Lecture 1 - Week 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "competitive-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unexpected-citation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-fighter",
   "metadata": {},
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-junction",
   "metadata": {},
   "source": [
    "## 1) Here we are getting the data what we want using the figshare API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-newman",
   "metadata": {},
   "source": [
    "Defining the endpoint and Header info\n",
    "\n",
    "Read more on figshare API here \n",
    "https://docs.figshare.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "coastal-acting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ggeorg02/Desktop/DSCI 525 lectures/Week1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "planned-sullivan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ggeorg02/Desktop\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/ggeorg02/Desktop/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "numerical-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary metadata\n",
    "article_id = 14096681  # this is the unique identifier of the article on figshare\n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"rainfall/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-taiwan",
   "metadata": {},
   "source": [
    "Here we are sending a GET request to list the available files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "average-bradley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'is_link_only': False,\n",
       "  'name': 'daily_rainfall_2014.png',\n",
       "  'supplied_md5': 'fd32a2ffde300a31f8d63b1825d47e5e',\n",
       "  'computed_md5': 'fd32a2ffde300a31f8d63b1825d47e5e',\n",
       "  'id': 26579150,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579150',\n",
       "  'size': 58863},\n",
       " {'is_link_only': False,\n",
       "  'name': 'environment.yml',\n",
       "  'supplied_md5': '060b2020017eed93a1ee7dd8c65b2f34',\n",
       "  'computed_md5': '060b2020017eed93a1ee7dd8c65b2f34',\n",
       "  'id': 26579171,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579171',\n",
       "  'size': 192},\n",
       " {'is_link_only': False,\n",
       "  'name': 'README.md',\n",
       "  'supplied_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c',\n",
       "  'computed_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c',\n",
       "  'id': 26586554,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26586554',\n",
       "  'size': 5422},\n",
       " {'is_link_only': False,\n",
       "  'name': 'data.zip',\n",
       "  'supplied_md5': 'b517383f76e77bd03755a63a8ff83ee9',\n",
       "  'computed_md5': 'b517383f76e77bd03755a63a8ff83ee9',\n",
       "  'id': 26766812,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766812',\n",
       "  'size': 814041183},\n",
       " {'is_link_only': False,\n",
       "  'name': 'get_data.py',\n",
       "  'supplied_md5': '7829028495fd9dec9680ea013474afa6',\n",
       "  'computed_md5': '7829028495fd9dec9680ea013474afa6',\n",
       "  'id': 26766815,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766815',\n",
       "  'size': 4113}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)  # this contains all the articles data, feel free to check it out\n",
    "files = data[\"files\"]             # this is just the data about the files, which is what we want\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-claim",
   "metadata": {},
   "source": [
    "We are going to get the file named individual_years.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "hungarian-fossil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "files_to_dl = [\"data.zip\"]  # feel free to add other files here\n",
    "for file in files:\n",
    "    if file[\"name\"] in files_to_dl:\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        urlretrieve(file[\"download_url\"], output_directory + file[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "parliamentary-mattress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 41.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with zipfile.ZipFile(os.path.join(output_directory, \"data.zip\"), 'r') as f:\n",
    "    f.extractall(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-acoustic",
   "metadata": {},
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-pointer",
   "metadata": {},
   "source": [
    "## 2) Combine the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-empire",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "useful-sampling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889-01-01 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.00</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.50</td>\n",
       "      <td>3.293256e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889-01-02 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.00</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.50</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1889-01-03 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.00</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.50</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1889-01-04 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.00</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.50</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1889-01-05 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.00</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.50</td>\n",
       "      <td>1.047658e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932835</th>\n",
       "      <td>2014-12-27 12:00:00</td>\n",
       "      <td>-30.00</td>\n",
       "      <td>-28.75</td>\n",
       "      <td>151.875</td>\n",
       "      <td>153.75</td>\n",
       "      <td>2.951144e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932836</th>\n",
       "      <td>2014-12-28 12:00:00</td>\n",
       "      <td>-30.00</td>\n",
       "      <td>-28.75</td>\n",
       "      <td>151.875</td>\n",
       "      <td>153.75</td>\n",
       "      <td>2.257118e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932837</th>\n",
       "      <td>2014-12-29 12:00:00</td>\n",
       "      <td>-30.00</td>\n",
       "      <td>-28.75</td>\n",
       "      <td>151.875</td>\n",
       "      <td>153.75</td>\n",
       "      <td>1.204670e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932838</th>\n",
       "      <td>2014-12-30 12:00:00</td>\n",
       "      <td>-30.00</td>\n",
       "      <td>-28.75</td>\n",
       "      <td>151.875</td>\n",
       "      <td>153.75</td>\n",
       "      <td>2.632404e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932839</th>\n",
       "      <td>2014-12-31 12:00:00</td>\n",
       "      <td>-30.00</td>\n",
       "      <td>-28.75</td>\n",
       "      <td>151.875</td>\n",
       "      <td>153.75</td>\n",
       "      <td>3.431610e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1932840 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time  lat_min  lat_max  lon_min  lon_max  \\\n",
       "0        1889-01-01 12:00:00   -36.25   -35.00  140.625   142.50   \n",
       "1        1889-01-02 12:00:00   -36.25   -35.00  140.625   142.50   \n",
       "2        1889-01-03 12:00:00   -36.25   -35.00  140.625   142.50   \n",
       "3        1889-01-04 12:00:00   -36.25   -35.00  140.625   142.50   \n",
       "4        1889-01-05 12:00:00   -36.25   -35.00  140.625   142.50   \n",
       "...                      ...      ...      ...      ...      ...   \n",
       "1932835  2014-12-27 12:00:00   -30.00   -28.75  151.875   153.75   \n",
       "1932836  2014-12-28 12:00:00   -30.00   -28.75  151.875   153.75   \n",
       "1932837  2014-12-29 12:00:00   -30.00   -28.75  151.875   153.75   \n",
       "1932838  2014-12-30 12:00:00   -30.00   -28.75  151.875   153.75   \n",
       "1932839  2014-12-31 12:00:00   -30.00   -28.75  151.875   153.75   \n",
       "\n",
       "         rain (mm/day)  \n",
       "0         3.293256e-13  \n",
       "1         0.000000e+00  \n",
       "2         0.000000e+00  \n",
       "3         0.000000e+00  \n",
       "4         1.047658e-02  \n",
       "...                ...  \n",
       "1932835   2.951144e-02  \n",
       "1932836   2.257118e-01  \n",
       "1932837   1.204670e-01  \n",
       "1932838   2.632404e-02  \n",
       "1932839   3.431610e-02  \n",
       "\n",
       "[1932840 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### just listing to get an idea how individual file looks like \n",
    "#use_cols = [\"ArrDelay\", \"DepDelay\", \"Distance\", \"TailNum\",\"UniqueCarrier\",\"Origin\",\"Dest\"]\n",
    "df = pd.read_csv(\"rainfall/ACCESS-CM2_daily_rainfall_NSW.csv\" ,dtype={'TailNum': 'str'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "therapeutic-angle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2097.82 MiB, increment: 0.59 MiB\n",
      "Wall time: 11min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%memit\n",
    "# Shows time that regular python takes to merge file\n",
    "# Join all data together\n",
    "## here we are using a normal python way of merging the data \n",
    "import pandas as pd\n",
    "#use_cols = [\"ArrDelay\", \"DepDelay\", \"Distance\", \"TailNum\",\"UniqueCarrier\",\"Origin\",\"Dest\"]\n",
    "files = glob.glob('rainfall/*.csv')\n",
    "df = pd.concat((pd.read_csv(file, index_col=0)\n",
    "                .assign(model=re.findall(r'[^\\\\]+(?=\\_d)', file)[0])\n",
    "                for file in files)\n",
    "              )\n",
    "df.to_csv(\"rainfall/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adopted-covering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['figshareairline\\\\ACCESS-CM2_daily_rainfall_NSW.csv',\n",
       " 'figshareairline\\\\ACCESS-ESM1-5_daily_rainfall_NSW.csv',\n",
       " 'figshareairline\\\\AWI-ESM-1-1-LR_daily_rainfall_NSW.csv',\n",
       " 'figshareairline\\\\BCC-CSM2-MR_daily_rainfall_NSW.csv',\n",
       " 'figshareairline\\\\BCC-ESM1_daily_rainfall_NSW.csv',\n",
       " 'figshareairline\\\\CanESM5_daily_rainfall_NSW.csv',\n",
       " 'figshareairline\\\\CMCC-CM2-HR4_daily_rainfall_NSW.csv',\n",
       " 'figshareairline\\\\CMCC-CM2-SR5_daily_rainfall_NSW.csv',\n",
       " 'figshareairline\\\\CMCC-ESM2_daily_rainfall_NSW.csv',\n",
       " 'figshareairline\\\\EC-Earth3-Veg-LR_daily_rainfall_NSW.csv',\n",
       " 'figshareairline\\\\FGOALS-f3-L_daily_rainfall_NSW.csv',\n",
       " 'figshareairline\\\\FGOALS-g3_daily_rainfall_NSW.csv',\n",
       " 'figshareairline\\\\GFDL-CM4_daily_rainfall_NSW.csv',\n",
       " 'figshareairline\\\\GFDL-ESM4_daily_rainfall_NSW.csv',\n",
       " 'figshareairline\\\\INM-CM4-8_daily_rainfall_NSW.csv',\n",
       " 'figshareairline\\\\INM-CM5-0_daily_rainfall_NSW.csv',\n",
       " 'figshareairline\\\\KIOST-ESM_daily_rainfall_NSW.csv',\n",
       " 'figshareairline\\\\MIROC6_daily_rainfall_NSW.csv',\n",
       " 'figshareairline\\\\MPI-ESM-1-2-HAM_daily_rainfall_NSW.csv',\n",
       " 'figshareairline\\\\MPI-ESM1-2-HR_daily_rainfall_NSW.csv',\n",
       " 'figshareairline\\\\MPI-ESM1-2-LR_daily_rainfall_NSW.csv',\n",
       " 'figshareairline\\\\MRI-ESM2-0_daily_rainfall_NSW.csv',\n",
       " 'figshareairline\\\\NESM3_daily_rainfall_NSW.csv',\n",
       " 'figshareairline\\\\NorESM2-LM_daily_rainfall_NSW.csv',\n",
       " 'figshareairline\\\\NorESM2-MM_daily_rainfall_NSW.csv',\n",
       " 'figshareairline\\\\observed_daily_rainfall_SYD.csv',\n",
       " 'figshareairline\\\\SAM0-UNICON_daily_rainfall_NSW.csv',\n",
       " 'figshareairline\\\\TaiESM1_daily_rainfall_NSW.csv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "injured-gateway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889-01-01 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>3.293256e-13</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889-01-02 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1889-01-03 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1889-01-04 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1889-01-05 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>1.047658e-02</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time  lat_min  lat_max  lon_min  lon_max  rain (mm/day)  \\\n",
       "0  1889-01-01 12:00:00   -36.25    -35.0  140.625    142.5   3.293256e-13   \n",
       "1  1889-01-02 12:00:00   -36.25    -35.0  140.625    142.5   0.000000e+00   \n",
       "2  1889-01-03 12:00:00   -36.25    -35.0  140.625    142.5   0.000000e+00   \n",
       "3  1889-01-04 12:00:00   -36.25    -35.0  140.625    142.5   0.000000e+00   \n",
       "4  1889-01-05 12:00:00   -36.25    -35.0  140.625    142.5   1.047658e-02   \n",
       "\n",
       "        model  \n",
       "0  ACCESS-CM2  \n",
       "1  ACCESS-CM2  \n",
       "2  ACCESS-CM2  \n",
       "3  ACCESS-CM2  \n",
       "4  ACCESS-CM2  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv('rainfall/combined_data.csv')\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "available-block",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1G\tfigshareairline/combined_data.csv\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "du -sh figshareairline/combined_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "stone-spray",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.8 s, sys: 9.7 s, total: 45.5 s\n",
      "Wall time: 57.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"rainfall/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "regional-insertion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86289323, 8)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "purple-lunch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>TailNum</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>DepDelay</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DL</td>\n",
       "      <td>N673DL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>PHX</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DL</td>\n",
       "      <td>N686DA</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>PHX</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DL</td>\n",
       "      <td>N685DA</td>\n",
       "      <td>52.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>PHX</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DL</td>\n",
       "      <td>N522DA</td>\n",
       "      <td>84.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>PHX</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DL</td>\n",
       "      <td>N2824W</td>\n",
       "      <td>56.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>PHX</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UniqueCarrier TailNum  ArrDelay  DepDelay Origin Dest  Distance  year\n",
       "0            DL  N673DL      66.0      69.0    ATL  PHX    1587.0  1996\n",
       "1            DL  N686DA       3.0       1.0    ATL  PHX    1587.0  1996\n",
       "2            DL  N685DA      52.0      26.0    ATL  PHX    1587.0  1996\n",
       "3            DL  N522DA      84.0     100.0    ATL  PHX    1587.0  1996\n",
       "4            DL  N2824W      56.0      84.0    ATL  PHX    1587.0  1996"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-spider",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-hazard",
   "metadata": {},
   "source": [
    "# Lecture 2 - Week 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "latin-conversion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-holder",
   "metadata": {},
   "source": [
    "## Dask "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-semiconductor",
   "metadata": {},
   "source": [
    "This is a scalable python library , please check it out \n",
    "https://dask.org    \n",
    "\n",
    "It does the chunking and parallel execution for us. So we dont have to manually take care of it using the chunk_size https://cmdlinetips.com/2018/01/how-to-load-a-massive-file-as-small-chunks-in-pandas/ for chunking up ( we are using chunk_size later in this notebook to load the combined big csv to memory as chunks) or the \"multiprocessing\" python library for parallel processing https://docs.python.org/3/library/multiprocessing.html. \n",
    "\n",
    "Best part of dask is the syntax is much similar to the default pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "treated-genre",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 33366.67 MiB, increment: 18188.23 MiB\n",
      "CPU times: user 5min 52s, sys: 11.5 s, total: 6min 3s\n",
      "Wall time: 5min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "# shows time that dask take to merge\n",
    "use_cols = [\"ArrDelay\", \"DepDelay\", \"Distance\", \"TailNum\",\"UniqueCarrier\",\"Origin\",\"Dest\"]\n",
    "# ddf = dd.read_csv(\"/Users/ggeorg02/Desktop/figshareairline/individual_years/*.csv\",assume_missing=True,encoding = \"ISO-8859-1\",dtype={'TailNum': 'str'},usecols=use_cols)\n",
    "ddf = dd.read_csv(\"figshareairline/individual_years/*.csv\",assume_missing=True,usecols=use_cols)\n",
    "ddf.to_csv(\"figshareairline/combined_data_dask.csv\", single_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "formed-moldova",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>TailNum</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>DepDelay</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UA</td>\n",
       "      <td>N7298U</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>ORD</td>\n",
       "      <td>PHL</td>\n",
       "      <td>678.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UA</td>\n",
       "      <td>N7449U</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ORD</td>\n",
       "      <td>PHL</td>\n",
       "      <td>678.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UA</td>\n",
       "      <td>N7453U</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ORD</td>\n",
       "      <td>PHL</td>\n",
       "      <td>678.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UA</td>\n",
       "      <td>N7288U</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ORD</td>\n",
       "      <td>PHL</td>\n",
       "      <td>678.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UA</td>\n",
       "      <td>N7275U</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ORD</td>\n",
       "      <td>PHL</td>\n",
       "      <td>678.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UniqueCarrier TailNum  ArrDelay  DepDelay Origin Dest  Distance\n",
       "0            UA  N7298U      15.0      12.0    ORD  PHL     678.0\n",
       "1            UA  N7449U       1.0       3.0    ORD  PHL     678.0\n",
       "2            UA  N7453U      -5.0       4.0    ORD  PHL     678.0\n",
       "3            UA  N7288U      -9.0       0.0    ORD  PHL     678.0\n",
       "4            UA  N7275U      -6.0       0.0    ORD  PHL     678.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-guatemala",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-minnesota",
   "metadata": {},
   "source": [
    "## 3) Loading the combined csv file and doing something (various ways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "foster-strategy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WN    13194660\n",
      "DL    10435886\n",
      "AA     9672922\n",
      "UA     8821384\n",
      "US     8286980\n",
      "NW     6946627\n",
      "CO     4976761\n",
      "MQ     3954895\n",
      "OO     3090853\n",
      "XE     2350309\n",
      "HP     2224941\n",
      "AS     2162672\n",
      "TW     1890420\n",
      "EV     1697172\n",
      "OH     1464176\n",
      "FL     1265138\n",
      "YV      854056\n",
      "B6      811341\n",
      "DH      693047\n",
      "9E      521059\n",
      "F9      336958\n",
      "HA      274265\n",
      "TZ      208420\n",
      "AQ      154381\n",
      "Name: UniqueCarrier, dtype: int64\n",
      "peak memory: 33909.09 MiB, increment: 18972.36 MiB\n",
      "CPU times: user 40.7 s, sys: 9.91 s, total: 50.6 s\n",
      "Wall time: 58.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "#simple pandas - This is how we do normally ,which means we are loading the entire data to the memory\n",
    "df = pd.read_csv(\"figshareairline/combined_data.csv\")\n",
    "print(df[\"UniqueCarrier\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "occupied-japanese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>TailNum</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>DepDelay</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DL</td>\n",
       "      <td>N673DL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>PHX</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DL</td>\n",
       "      <td>N686DA</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>PHX</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DL</td>\n",
       "      <td>N685DA</td>\n",
       "      <td>52.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>PHX</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DL</td>\n",
       "      <td>N522DA</td>\n",
       "      <td>84.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>PHX</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DL</td>\n",
       "      <td>N2824W</td>\n",
       "      <td>56.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>PHX</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UniqueCarrier TailNum  ArrDelay  DepDelay Origin Dest  Distance  year\n",
       "0            DL  N673DL      66.0      69.0    ATL  PHX    1587.0  1996\n",
       "1            DL  N686DA       3.0       1.0    ATL  PHX    1587.0  1996\n",
       "2            DL  N685DA      52.0      26.0    ATL  PHX    1587.0  1996\n",
       "3            DL  N522DA      84.0     100.0    ATL  PHX    1587.0  1996\n",
       "4            DL  N2824W      56.0      84.0    ATL  PHX    1587.0  1996"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "operating-direction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UniqueCarrier     object\n",
       "TailNum           object\n",
       "ArrDelay         float64\n",
       "DepDelay         float64\n",
       "Origin            object\n",
       "Dest              object\n",
       "Distance         float64\n",
       "year               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "severe-bridal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage with float64: 2070.94 MB\n",
      "Memory usage with float32: 1035.47 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory usage with float64: {df[['ArrDelay','DepDelay','Distance']].memory_usage().sum() / 1e6:.2f} MB\")\n",
    "print(f\"Memory usage with float32: {df[['ArrDelay','DepDelay','Distance']].astype('float32', errors='ignore').memory_usage().sum() / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-alexander",
   "metadata": {},
   "source": [
    "In the next cell we are seeing an example of how to load data in small chunks. We can pass chunksize as a parameter while using read_csv. Read more on it here \n",
    "https://cmdlinetips.com/2018/01/how-to-load-a-massive-file-as-small-chunks-in-pandas/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "orange-energy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9E      521059\n",
      "AA     9672922\n",
      "AQ      154381\n",
      "AS     2162672\n",
      "B6      811341\n",
      "CO     4976761\n",
      "DH      693047\n",
      "DL    10435886\n",
      "EV     1697172\n",
      "F9      336958\n",
      "FL     1265138\n",
      "HA      274265\n",
      "HP     2224941\n",
      "MQ     3954895\n",
      "NW     6946627\n",
      "OH     1464176\n",
      "OO     3090853\n",
      "TW     1890420\n",
      "TZ      208420\n",
      "UA     8821384\n",
      "US     8286980\n",
      "WN    13194660\n",
      "XE     2350309\n",
      "YV      854056\n",
      "dtype: int64\n",
      "peak memory: 21020.25 MiB, increment: 6865.48 MiB\n",
      "CPU times: user 39.3 s, sys: 2.75 s, total: 42 s\n",
      "Wall time: 43.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "counts = pd.Series(dtype=int)\n",
    "for chunk in pd.read_csv(\"figshareairline/combined_data.csv\", chunksize=10_000_000):\n",
    "    counts = counts.add(chunk[\"UniqueCarrier\"].value_counts(), fill_value=0)\n",
    "print(counts.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "humanitarian-freight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WN    13194660\n",
      "DL    10435886\n",
      "AA     9672922\n",
      "UA     8821384\n",
      "US     8286980\n",
      "NW     6946627\n",
      "CO     4976761\n",
      "MQ     3954895\n",
      "OO     3090853\n",
      "XE     2350309\n",
      "HP     2224941\n",
      "AS     2162672\n",
      "TW     1890420\n",
      "EV     1697172\n",
      "OH     1464176\n",
      "FL     1265138\n",
      "YV      854056\n",
      "B6      811341\n",
      "DH      693047\n",
      "9E      521059\n",
      "F9      336958\n",
      "HA      274265\n",
      "TZ      208420\n",
      "AQ      154381\n",
      "Name: UniqueCarrier, dtype: int64\n",
      "peak memory: 23640.69 MiB, increment: 5471.92 MiB\n",
      "CPU times: user 46.4 s, sys: 6.74 s, total: 53.1 s\n",
      "Wall time: 29.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "# dask way\n",
    "# Here again I am using dask to read that csv file. Remember internally its loading chunks and doing it parallely.\n",
    "# here see cpu time greater than wall time \n",
    "ddf = dd.read_csv('figshareairline/combined_data.csv')\n",
    "print(ddf[\"UniqueCarrier\"].value_counts().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-spectacular",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-subject",
   "metadata": {},
   "source": [
    "## 4) Advanced file formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-terminology",
   "metadata": {},
   "source": [
    "#### Arrow file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "increased-christianity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ggeorg02/opt/miniconda3/envs/525/lib/python3.9/site-packages/rpy2_arrow/pyarrow_rarrow.py:16: UserWarning: This was designed againt arrow versions starting with 2.0. but you have 3.0.0\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "## install the packages https://arrow.apache.org/docs/python/install.html\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "## How to install put instructions https://anaconda.org/conda-forge/rpy2\n",
    "import rpy2.rinterface\n",
    "# install this https://pypi.org/project/rpy2-arrow/#description  pip install rpy2-arrow\n",
    "# have to install this as well conda install -c conda-forge r-arrow \n",
    "import rpy2_arrow.pyarrow_rarrow as pyra\n",
    "### instruction\n",
    "import pyarrow.feather as feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prime-california",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: \n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "#just seeing if its available\n",
    "library(\"arrow\")\n",
    "library(\"dplyr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "union-windsor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 16988.36 MiB, increment: 15724.98 MiB\n",
      "CPU times: user 14.3 s, sys: 4.38 s, total: 18.6 s\n",
      "Wall time: 18.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "## read more on the datasets here  https://arrow.apache.org/docs/python/dataset.html\n",
    "dataset = ds.dataset(\"figshareairline/combined_data.csv\", format=\"csv\")\n",
    "## this is of arrow table format\n",
    "table = dataset.to_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "critical-block",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.33 s, sys: 7.03 s, total: 12.4 s\n",
      "Wall time: 5.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# experiment in writing in feather format \n",
    "feather.write_feather(table, 'figshareairline/example.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "better-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### parquet file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "satisfied-amplifier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.3 s, sys: 530 ms, total: 15.8 s\n",
      "Wall time: 15.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## writing as a single parquet \n",
    "pq.write_table(table, 'figshareairline/example.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "alpha-migration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.9 s, sys: 16.1 s, total: 54 s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## writing as a partitioned parquet \n",
    "pq.write_to_dataset(table, 'figshareairline/example_partitioned.parquet',partition_cols=['year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-spyware",
   "metadata": {},
   "source": [
    "## Now we have written the data in 3 different formats \n",
    "- csv\n",
    "- feather \n",
    "- parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "occupational-cheat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1G\tfigshareairline/combined_data.csv\n",
      "2.1G\tfigshareairline/example.feather\n",
      "416M\tfigshareairline/example.parquet\n",
      "397M\tfigshareairline/example_partitioned.parquet\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "# I am just seeing the size of the csv data\n",
    "du -sh figshareairline/combined_data.csv\n",
    "# I am just seeing the size of the feather data\n",
    "du -sh figshareairline/example.feather\n",
    "# I am just seeing the size of the parquet data\n",
    "du -sh figshareairline/example.parquet\n",
    "# I am just seeing the size of the parquet data - partitioned\n",
    "du -sh figshareairline/example_partitioned.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-driver",
   "metadata": {},
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-track",
   "metadata": {},
   "source": [
    "## 5) Experimenting the exchange of data b/w python and R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "## first I am trying the normal way that anyone would"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "exclusive-nitrogen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 15950.16 MiB, increment: 0.03 MiB\n",
      "CPU times: user 4.45 s, sys: 2.38 s, total: 6.83 s\n",
      "Wall time: 8.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "#simple pandas - This is how we do normally ,which means we are loading the entire data to the memory\n",
    "# just loading 10 million rows\n",
    "df = pd.read_csv(\"figshareairline/combined_data.csv\",nrows = 10_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "respective-medline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"data.frame\"\n",
      "   UniqueCarrier       n\n",
      "1             AA 1220552\n",
      "2             AS  273960\n",
      "3             CO  756523\n",
      "4             DL 1675173\n",
      "5             HP  383652\n",
      "6             NW  998094\n",
      "7             TW  523951\n",
      "8             UA 1374698\n",
      "9             US 1350489\n",
      "10            WN 1442908\n",
      "Time difference of 0.2657518 secs\n",
      "CPU times: user 5min 38s, sys: 18.8 s, total: 5min 57s\n",
      "Wall time: 6min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R -i df\n",
    "## here I am transferring the python dataframe to R\n",
    "## Look how much time it takes ! or tell me how much time you end up waiting !!\n",
    "# if you see here this operation takes less time inside the R terminal, but overall it takes time , \n",
    "## The rest of time in spent on serialization and deserialization\n",
    "start_time <- Sys.time()\n",
    "library(dplyr)\n",
    "print(class(df))\n",
    "result <- df %>% count(UniqueCarrier)\n",
    "print(result)\n",
    "end_time <- Sys.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now lets use the arrow format to excahnge the dataframes. Here is the github repo, \n",
    "# still in its baby state so use with caution. https://github.com/rpy2/rpy2-arrow\n",
    "# Another way exchange data is by writing it to feather from python and then reading in R.\n",
    "# try that way and check how much time it takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "respiratory-stack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 15092.19 MiB, increment: 6074.00 MiB\n",
      "CPU times: user 14.3 s, sys: 8.6 s, total: 22.9 s\n",
      "Wall time: 23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "## read more on the datasets here  https://arrow.apache.org/docs/python/dataset.html\n",
    "#Loading around 90 Million rows\n",
    "dataset = ds.dataset(\"figshareairline/combined_data.csv\", format=\"csv\")\n",
    "## this is of arrow table format\n",
    "table = dataset.to_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "mobile-regard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3164\n",
      "rarrow.ChunkedArray: 0.03018498420715332\n",
      "3164\n",
      "rarrow.ChunkedArray: 0.03617095947265625\n",
      "3164\n",
      "rarrow.ChunkedArray: 0.030874013900756836\n",
      "3164\n",
      "rarrow.ChunkedArray: 0.03427600860595703\n",
      "3164\n",
      "rarrow.ChunkedArray: 0.03125905990600586\n",
      "3164\n",
      "rarrow.ChunkedArray: 0.03152108192443848\n",
      "3164\n",
      "rarrow.ChunkedArray: 0.03460121154785156\n",
      "3164\n",
      "rarrow.ChunkedArray: 0.03463602066040039\n",
      "peak memory: 14650.72 MiB, increment: 4461.88 MiB\n",
      "CPU times: user 8.51 s, sys: 2.1 s, total: 10.6 s\n",
      "Wall time: 11.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "## Here we are loading the arrow dataframe that we have loaded previously\n",
    "r_table = pyra.converter.py2rpy(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "significant-communist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Table\"       \"ArrowObject\" \"R6\"         \n",
      "[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n",
      "\u001b[90m# A tibble: 24 x 2\u001b[39m\n",
      "   UniqueCarrier        n\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m            \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m 9E              \u001b[4m5\u001b[24m\u001b[4m2\u001b[24m\u001b[4m1\u001b[24m059\n",
      "\u001b[90m 2\u001b[39m AA             9\u001b[4m6\u001b[24m\u001b[4m7\u001b[24m\u001b[4m2\u001b[24m922\n",
      "\u001b[90m 3\u001b[39m AQ              \u001b[4m1\u001b[24m\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m381\n",
      "\u001b[90m 4\u001b[39m AS             2\u001b[4m1\u001b[24m\u001b[4m6\u001b[24m\u001b[4m2\u001b[24m672\n",
      "\u001b[90m 5\u001b[39m B6              \u001b[4m8\u001b[24m\u001b[4m1\u001b[24m\u001b[4m1\u001b[24m341\n",
      "\u001b[90m 6\u001b[39m CO             4\u001b[4m9\u001b[24m\u001b[4m7\u001b[24m\u001b[4m6\u001b[24m761\n",
      "\u001b[90m 7\u001b[39m DH              \u001b[4m6\u001b[24m\u001b[4m9\u001b[24m\u001b[4m3\u001b[24m047\n",
      "\u001b[90m 8\u001b[39m DL            10\u001b[4m4\u001b[24m\u001b[4m3\u001b[24m\u001b[4m5\u001b[24m886\n",
      "\u001b[90m 9\u001b[39m EV             1\u001b[4m6\u001b[24m\u001b[4m9\u001b[24m\u001b[4m7\u001b[24m172\n",
      "\u001b[90m10\u001b[39m F9              \u001b[4m3\u001b[24m\u001b[4m3\u001b[24m\u001b[4m6\u001b[24m958\n",
      "\u001b[90m# … with 14 more rows\u001b[39m\n",
      "Time difference of 1.184519 mins\n",
      "CPU times: user 20.9 s, sys: 20.4 s, total: 41.3 s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R -i r_table\n",
    "start_time <- Sys.time()\n",
    "print(class(r_table))\n",
    "##add details on collect here\n",
    "library(dplyr)\n",
    "# Arrow only support some operations check this out https://arrow.apache.org/docs/r/articles/dataset.html\n",
    "result <- r_table %>% collect() %>% count(UniqueCarrier)\n",
    "print(class(r_table %>% collect()))\n",
    "end_time <- Sys.time()\n",
    "print(result)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "italian-congo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n",
      "\u001b[90m# A tibble: 24 x 2\u001b[39m\n",
      "   UniqueCarrier        n\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m            \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m 9E              \u001b[4m5\u001b[24m\u001b[4m2\u001b[24m\u001b[4m1\u001b[24m059\n",
      "\u001b[90m 2\u001b[39m AA             9\u001b[4m6\u001b[24m\u001b[4m7\u001b[24m\u001b[4m2\u001b[24m922\n",
      "\u001b[90m 3\u001b[39m AQ              \u001b[4m1\u001b[24m\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m381\n",
      "\u001b[90m 4\u001b[39m AS             2\u001b[4m1\u001b[24m\u001b[4m6\u001b[24m\u001b[4m2\u001b[24m672\n",
      "\u001b[90m 5\u001b[39m B6              \u001b[4m8\u001b[24m\u001b[4m1\u001b[24m\u001b[4m1\u001b[24m341\n",
      "\u001b[90m 6\u001b[39m CO             4\u001b[4m9\u001b[24m\u001b[4m7\u001b[24m\u001b[4m6\u001b[24m761\n",
      "\u001b[90m 7\u001b[39m DH              \u001b[4m6\u001b[24m\u001b[4m9\u001b[24m\u001b[4m3\u001b[24m047\n",
      "\u001b[90m 8\u001b[39m DL            10\u001b[4m4\u001b[24m\u001b[4m3\u001b[24m\u001b[4m5\u001b[24m886\n",
      "\u001b[90m 9\u001b[39m EV             1\u001b[4m6\u001b[24m\u001b[4m9\u001b[24m\u001b[4m7\u001b[24m172\n",
      "\u001b[90m10\u001b[39m F9              \u001b[4m3\u001b[24m\u001b[4m3\u001b[24m\u001b[4m6\u001b[24m958\n",
      "\u001b[90m# … with 14 more rows\u001b[39m\n",
      "Time difference of 1.683477 mins\n",
      "CPU times: user 21.2 s, sys: 36.4 s, total: 57.6 s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R\n",
    "### her we are showing how much time it took to read a feather file what we wrote in python\n",
    "library(arrow)\n",
    "start_time <- Sys.time()\n",
    "r_table <- arrow::read_feather(\"figshareairline/example.feather\")\n",
    "print(class(r_table))\n",
    "library(dplyr)\n",
    "result <- r_table %>% count(UniqueCarrier)\n",
    "end_time <- Sys.time()\n",
    "print(result)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-entertainment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:525]",
   "language": "python",
   "name": "conda-env-525-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
